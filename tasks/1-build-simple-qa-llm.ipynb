{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0614425c-7f0f-4ecb-b8dc-f4c596488563",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. RAG Workshop: Build a simple Q&A LLM\n",
    "\n",
    "In this task, you’ll create a question-and-answer system using MistralAI’s language models. Learn to:\n",
    "\n",
    "- Use MistralAI LLMs for generating answers.\n",
    "- Enrich responses by adding external knowledge to prompts.\n",
    "- Optimize prompts through experimentation for better accuracy.\n",
    "\n",
    "By the end, you built a simple Q&A systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Set Up Access to MistralAI\n",
    "\n",
    "We'll be using Mistral, a popular OpenAI LLM, to build our Q&A system. First, let's set up access by creating an account and generating an API key. Follow the steps below to get started.\n",
    "\n",
    "1. **Create an account** on [MistralAI](https://mistral.ai/) if you don’t have one.\n",
    "2. **Log in to the MistralAI console**: Go to [https://console.mistral.ai/api-keys/](https://console.mistral.ai/api-keys/).\n",
    "3. **Generate an API key**: Click to create a new API Key.\n",
    "4. **Save your API key**: Copy the API key and create a `.env` file in the root of the project repository.\n",
    "5. **Add the API key to your `.env` file**. Your `.env` file should look like this: `MISTRAL_API_KEY=YOUR_API_TOKEN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "def todo_setup_access_completed():\n",
    "    token = os.getenv('MISTRAL_API_KEY')\n",
    "    if token is None:\n",
    "        raise Exception(\".env is not in the root folder or `MISTRAL_API_KEY` is not set.\")\n",
    "\n",
    "todo_setup_access_completed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TODO: Call the Mistral API\n",
    "\n",
    "In this section, we will learn how to call open-source models using the `mistral-small-latest` model, which is smaller and faster. We will utilize [Mistral’s open-source Python client](https://github.com/mistralai/client-python), to complete the coding sections. For more information, refer to the [documentation on the Python client](https://docs.mistral.ai/getting-started/clients/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_api_key = os.getenv('MISTRAL_API_KEY')\n",
    "mistral_client = Mistral(api_key=mistral_api_key)\n",
    "mistral_model = \"mistral-small-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mistral_api(client: Mistral, model: str, message: str) -> str:\n",
    "    # TODO: Use the client to call MistralAPI and respond the message as string\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, the current President of the United States is Joe Biden. He took office on January 20, 2021. However, for the most current information, please refer to a reliable and up-to-date source.\n"
     ]
    }
   ],
   "source": [
    "# Testing if it is successful\n",
    "print(call_mistral_api(client=mistral_client, model=mistral_model, message=\"Who is the current US president?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Simple Q&A RAG\n",
    "\n",
    "Large language models (LLMs) can sometimes hallucinate, presenting false information due to outdated training data. Retrieval-Augmented Generation (RAG) allows us to incorporate external information to mitigate these challenges. In this task, we will create a simple Q&A RAG that utilizes knowledge from a PDF to enrich its answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    # TODO: Use PyPDF2 to load a PDF as text https://pypdf2.readthedocs.io/en/3.x/user/extract-text.html\n",
    "    raise NotImplementedError\n",
    "\n",
    "text = extract_text_from_pdf(\"../data/food_lab_green_chapter-small.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the text ready, we can now focus on enriching the prompt to enhance our LLM's intelligence and responsiveness. Below is an initial Q&A prompt to get started with some code to run your Q&A LLM for different user queries.\n",
    "\n",
    "\n",
    "The prompt you write will influence the behavior of the Q&A system, so consider enhancing it by:\n",
    "- Ensuring the AI responds only to questions that are relevant to its knowledge or context.\n",
    "- Adjusting the tone of the prompt for a more effective interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_prompt(message, context):\n",
    "    return f\"\"\"Answer the question only using the provided content.\n",
    "        Context: {context}\n",
    "        User Question: {message}\n",
    "        \"\"\"  \n",
    "\n",
    "message = \"What is the goal in life?\"\n",
    "# message = \"How do you design a salad?\"\n",
    "rag_prompt = create_rag_prompt(message=message, context=text)\n",
    "rag_response = call_mistral_api(client=mistral_client, model=mistral_model, message=rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below you can compare how the out of the box and your Q&A LLM provide different answers depending the information that it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERIC RESPONSE:\n",
      " Designing a salad recipe involves considering various elements like ingredients, flavors, textures, and presentation. Here's a step-by-step guide to help you create your own salad recipe:\n",
      "\n",
      "1. **Choose a Base:**\n",
      "   - Leafy greens: Mix greens, spinach, arugula, romaine, kale, etc.\n",
      "   - Grains: Quinoa, couscous, farro, or rice.\n",
      "   - Other bases: Pasta, beans, or lentils.\n",
      "\n",
      "2. **Add Proteins (optional):**\n",
      "   - Animal-based: Chicken, turkey, beef, pork, fish, shrimp, eggs, or cheese.\n",
      "   - Plant-based: Tofu, tempeh, chickpeas, lentils, or nuts/seeds.\n",
      "\n",
      "3. **Include Veggies:**\n",
      "   - Raw: Carrots, cucumbers, bell peppers, radishes, etc.\n",
      "   - Cooked: Roasted vegetables like sweet potatoes, beets, or Brussels sprouts.\n",
      "   - Pickled or fermented: Sauerkraut, pickles, or kimchi.\n",
      "\n",
      "4. **Add Fruits (optional):**\n",
      "   - Fresh: Apples, berries, grapes, oranges, etc.\n",
      "   - Dried: Cranberries, raisins, or apricots.\n",
      "\n",
      "5. **Select Cheeses (optional):**\n",
      "   - Crumbly: Feta, goat cheese, or blue cheese.\n",
      "   - Shredded: Cheddar, mozzarella, or gouda.\n",
      "\n",
      "6. **Choose Nuts/Seeds (optional):**\n",
      "   - Almonds, walnuts, pecans, chia seeds, flax seeds, or pumpkin seeds.\n",
      "\n",
      "7. **Create a Dressing:**\n",
      "   - Vinaigrette: Mix oil (olive, avocado, or grapeseed) with an acid (vinegar, lemon juice, or lime juice), add salt, pepper, and any desired herbs or spices.\n",
      "   - Creamy: Combine mayonnaise, Greek yogurt, or sour cream with herbs, spices, and an acid.\n",
      "   - Other options: Honey mustard, tahini, or Asian-inspired dressings.\n",
      "\n",
      "8. **Plan a Topping:**\n",
      "   - Croutons, tortilla strips, or crispy onions.\n",
      "   - Fresh herbs like parsley, basil, or cilantro.\n",
      "   - Spices or seasonings like everything bagel seasoning, za'atar, or sumac.\n",
      "\n",
      "9. **Consider Flavor Balance:**\n",
      "   - Sweet, salty, sour, and bitter components.\n",
      "   - Texture contrasts: Crunchy, creamy, chewy, etc.\n",
      "\n",
      "10. **Write Down Your Recipe:**\n",
      "    - List ingredients with quantities.\n",
      "    - Describe preparation steps for each component.\n",
      "    - Provide instructions for assembling the salad.\n",
      "    - Include serving size and approximate preparation time.\n",
      "\n",
      "Here's an example of a salad recipe:\n",
      "\n",
      "**Mediterranean Quinoa Salad**\n",
      "\n",
      "Ingredients:\n",
      "- 2 cups cooked quinoa\n",
      "- 1 can (15 oz) chickpeas, drained and rinsed\n",
      "- 1 cucumber, diced\n",
      "- 1 bell pepper, diced\n",
      "- 1/2 red onion, thinly sliced\n",
      "- 1/2 cup crumbled feta cheese\n",
      "- 1/4 cup chopped fresh parsley\n",
      "- 1/4 cup olive oil\n",
      "- 3 tbsp lemon juice\n",
      "- 1 clove garlic, minced\n",
      "- 1 tsp dried oregano\n",
      "- Salt and pepper, to taste\n",
      "- Optional: Cherry tomatoes, Kalamata olives\n",
      "\n",
      "Instructions:\n",
      "1. In a large bowl, combine quinoa, chickpeas, cucumber, bell pepper, red onion, feta, and parsley.\n",
      "2. In a small bowl, whisk together olive oil, lemon juice, garlic, oregano, salt, and pepper.\n",
      "3. Pour dressing over salad and toss to coat.\n",
      "4. Add cherry tomatoes and olives if desired.\n",
      "5. Serve immediately or refrigerate for at least 30 minutes to let the flavors meld. Enjoy!\n",
      "----------\n",
      "RAG RESPONSE:\n",
      " To design a salad recipe, follow these six steps:\n",
      "\n",
      "1. **Find the best, freshest greens** and treat them with care.\n",
      "2. **Pick a dressing style** that enhances your greens.\n",
      "3. **Add strongly flavored or aromatic garnishes** (optional), like cheese, herbs, dried fruit, or cured meats.\n",
      "4. **Add \"crunchies\" for textural contrast** (optional), such as croutons, toasted nuts, or seeds.\n",
      "5. **Add supporting ingredients** (optional), like raw or cooked fruits, vegetables, meat, or seafood.\n",
      "6. **Dress your salad properly and serve it immediately**.\n"
     ]
    }
   ],
   "source": [
    "def compare_llm_answers(message):\n",
    "    generic_response = call_mistral_api(client=mistral_client, model=mistral_model, message=message)\n",
    "    \n",
    "    rag_prompt = create_rag_prompt(message=message, context=text)\n",
    "    rag_response = call_mistral_api(client=mistral_client, model=mistral_model, message=rag_prompt)\n",
    "\n",
    "    print(f\"GENERIC RESPONSE:\\n {generic_response}\")\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"RAG RESPONSE:\\n {rag_response}\")\n",
    "\n",
    "compare_llm_answers(\"How do you design a salad recipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! RAGs enrich the prompt with additional information about the topic to generate responses. The external information can come from various sources, not just PDFs, such as Google search results, social media posts, and more. With that, we’ve built a simple Q&A RAG. In the next chapter, we will scale it up to include even more context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1848951197487297,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Steven Test Playground",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
